{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'text-embedding-ada-002'\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.load_local(\"arxiv_vectorstore\", embeddings=embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations\n",
      "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations\n",
      "RoBERTa: A Robustly Optimized BERT Pretraining Approach\n"
     ]
    }
   ],
   "source": [
    "query = \"how can BERT be trained to optimize the number of parameters used?\"\n",
    "\n",
    "# Similarity search\n",
    "test_search = vectorstore.similarity_search_with_score(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "\n",
    "# How to extract text content and metadata from the first result returned by the similarity search\n",
    "first_chunk = test_search[0][0].page_content\n",
    "first_metadata = test_search[0][0].metadata\n",
    "\n",
    "# Papers from where the first 3 chunks were taken out of\n",
    "for doc in test_search:\n",
    "    print(doc[0].metadata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models as Tool Makers\n",
      "Gorilla: Large Language Model Connected with Massive APIs\n",
      "A Survey of Large Language Models\n"
     ]
    }
   ],
   "source": [
    "query = \"what research has been done in the field of LLM tool usage?\"\n",
    "\n",
    "test_search2 = vectorstore.similarity_search_with_score(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "\n",
    "# Papers from where the first 3 chunks were taken out of\n",
    "for doc in test_search2:\n",
    "    print(doc[0].metadata['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts - context, examples (if fewshot), task (prompt action, for example \"Answer based on this user input: {user_input}\"). Additional variables can be added to a prompt\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# Stage 1 - similarity search of the user input against the chunks stored in our FAISS database\n",
    "user_input = \"What is BERT?\"\n",
    "search = vectorstore.similarity_search_with_score(\n",
    "    user_input,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "\n",
    "# Stage 2 - summarize data of selected chunks in order to more easily fit into a context window\n",
    "input_template1 = \"\"\"\n",
    "You are an AI assistant designed to excel in the task of summarizing chunks of academic papers in the are of Computer Science and Artificial Intelligence.\n",
    "Be brief in your summarization. This summary will be used to decide if the chunk of text is useful to answer a specific question.\n",
    "\n",
    "Summarize the following chunk of text: {chunk}.\n",
    "Summary:\n",
    "\"\"\"\n",
    "prompt_template1 = PromptTemplate(\n",
    "    input_variables=[\"chunk\"],\n",
    "    template=input_template1\n",
    ")\n",
    "\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt_template1)\n",
    "\n",
    "summary_data = []\n",
    "for doc in search:\n",
    "    answer = chain1.run({'chunk': doc[0].page_content})\n",
    "    metadata = doc[0].metadata\n",
    "    data_to_append = {\n",
    "        'llm_summary': answer,\n",
    "        'metadata': metadata\n",
    "    }\n",
    "    summary_data.append(data_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3 - feed summary into another chain -> goal is for another llm to figure out how useful each summary in answering the initial user input - keep chosen dicts (chunk summary + metadata)\n",
    "input_template1 = \"\"\"\n",
    "You are an AI assistant designed to excel in the task of summarizing chunks of academic papers in the are of Computer Science and Artificial Intelligence.\n",
    "Be brief in your summarization. This summary will be used to decide if the chunk of text is useful to answer a specific question.\n",
    "\n",
    "Summarize the following chunk of text: {chunk}.\n",
    "Summary:\n",
    "\"\"\"\n",
    "prompt_template1 = PromptTemplate(\n",
    "    input_variables=[\"chunk\"],\n",
    "    template=input_template1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the filtered chunk summaries added to the prompt context, answer the user's question\n",
    "\n",
    "# Based on filtered chunk's summary and metadata, use APIs (Wikipedia, Wolfram Alpha, Youtube) to find relevant content - build an agent if time allows\n",
    "\n",
    "# chat_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "# template=\"You are a helpful assistant that helps people with learning about a variety of topics centered around {topic1} and {topic2}.\"\n",
    "# system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "# human_template=\"{text}\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "# chat_chain = LLMChain(llm=chat_llm, prompt=chat_prompt)\n",
    "\n",
    "# chat_chain({\"topic1\": \"CS\", \"topic2\": \"AI\", \"text\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'llm_summary': \"This text discusses the use of Electra, an AI model based on BERT, for summarizing chunks of academic papers in the field of Computer Science and Artificial Intelligence. It extends the BERT dataset to 33 billion tokens by including data from Clueweb, CommonCrawl, and Gigaword. The model architecture and most hyperparameters are the same as BERT's, with simple linear classifiers added for GLUE and a question-answering module from XLNet added for SQUAD. Weight sharing is proposed to improve the efficiency of the pre-training, with the input and output token embeddings of the generator always tied as in BERT. Results show that GLUE scores are 83.6 with no weight tying.\",\n",
       "  'metadata': {'chunk_id': 6,\n",
       "   'authors': ['Kevin Clark',\n",
       "    'Minh-Thang Luong',\n",
       "    'Quoc V. Le',\n",
       "    'Christopher D. Manning'],\n",
       "   'pdf_url': 'http://arxiv.org/pdf/2003.10555',\n",
       "   'summary': 'masked language modeling mlm pre training methods such as bert corrupt the input by replacing some tokens with mask and then train a model to reconstruct the original tokens while they produce good results when transferred to downstream nlp tasks they generally require large amounts of compute to be effective as an alternative we propose a more sample efficient pre training task called replaced token detection instead of masking the input our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network then instead of training a model that predicts the original identities of the corrupted tokens we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not thorough experiments demonstrate this new pre training task is more efficient than mlm because the task is defined over all input tokens rather than just the small subset that was masked out as a result the contextual representations learned by our approach substantially outperform the ones learned by bert given the same model size data and compute the gains are particularly strong for small models for example we train a model on one gpu for 4 days that outperforms gpt trained using 30x more compute on the glue natural language understanding benchmark our approach also works well at scale where it performs comparably to roberta and xlnet while using less than 1 4 of their compute and outperforms them when using the same amount of compute ',\n",
       "   'title': 'ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators'}},\n",
       " {'llm_summary': \"This paper proposes a novel Transformer Distillation method for knowledge distillation of Transformer-based models. This method is used to transfer knowledge from a large teacher model (BERT) to a small student model (TinyBERT). A two-stage learning framework is then introduced to ensure TinyBERT captures both general domain and task-specific knowledge. Experiments show that TinyBERT4 achieves 96.8% of BERTBase's performance on GLUE benchmark while being 7.5x smaller and 9.4x faster on inference. TinyBERT6 performs on par with BERTBase with only 28 parameters and 31 inference time.\",\n",
       "  'metadata': {'chunk_id': 0,\n",
       "   'authors': ['Xiaoqi Jiao',\n",
       "    'Yichun Yin',\n",
       "    'Lifeng Shang',\n",
       "    'Xin Jiang',\n",
       "    'Xiao Chen',\n",
       "    'Linlin Li',\n",
       "    'Fang Wang',\n",
       "    'Qun Liu'],\n",
       "   'pdf_url': 'http://arxiv.org/pdf/1909.10351',\n",
       "   'summary': 'language model pre training such as bert has significantly improved the performances of many natural language processing tasks however pre trained language models are usually computationally expensive so it is difficult to efficiently execute them on resource restricted devices to accelerate inference and reduce model size while maintaining accuracy we first propose a novel transformer distillation method that is specially designed for knowledge distillation kd of the transformer based models by leveraging this new kd method the plenty of knowledge encoded in a large teacher bert can be effectively transferred to a small student tiny bert then we introduce a new two stage learning framework for tinybert which performs transformer distillation at both the pretraining and task specific learning stages this framework ensures that tinybert can capture he general domain as well as the task specific knowledge in bert tinybert with 4 layers is empirically effective and achieves more than 96 8 the performance of its teacher bertbase on glue benchmark while being 7 5x smaller and 9 4x faster on inference tinybert with 4 layers is also significantly better than 4 layer state of the art baselines on bert distillation with only about 28 parameters and about 31 inference time of them moreover tinybert with 6 layers performs on par with its teacher bertbase ',\n",
       "   'title': 'TinyBERT: Distilling BERT for Natural Language Understanding'}},\n",
       " {'llm_summary': 'This paper proposes a new transformer-based neural language model, DEBERTA, which improves upon previous state-of-the-art PLMs using two novel techniques: a disentangled attention mechanism and an enhanced mask decoder. The disentangled attention mechanism represents each word in the input layer using two vectors that encode its content and position respectively, and the attention weights among words are computed using disentangled matrices based on their contents and relative positions. The enhanced mask decoder is pre-trained using masked language modeling, a fill-in-the-blank task where a model is taught to use the words surrounding a mask token to predict what the masked word should be.',\n",
       "  'metadata': {'chunk_id': 1,\n",
       "   'authors': ['Pengcheng He', 'Xiaodong Liu', 'Jianfeng Gao', 'Weizhu Chen'],\n",
       "   'pdf_url': 'http://arxiv.org/pdf/2006.03654',\n",
       "   'summary': 'recent progress in pre trained neural language models has significantly improved the performance of many natural language processing nlp tasks in this paper we propose a new model architecture deberta decoding enhanced bert with disentangled attention that improves the bert and roberta models using two novel techniques the first is the disentangled attention mechanism where each word is represented using two vectors that encode its content and position respectively and the attention weights among words are computed using disentangled matrices on their contents and relative positions respectively second an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre training in addition a new virtual adversarial training method is used for fine tuning to improve models generalization we show that these techniques significantly improve the efficiency of model pre training and the performance of both natural language understanding nlu and natural langauge generation nlg downstream tasks compared to roberta large a deberta model trained on half of the training data performs consistently better on a wide range of nlp tasks achieving improvements on mnli by 0 9 90 2 vs 91 1 on squad v2 0 by 2 3 88 4 vs 90 7 and race by 3 6 83 2 vs 86 8 notably we scale up deberta by training a larger version that consists of 48 transform layers with 1 5 billion parameters the significant performance boost makes the single deberta model surpass the human performance on the superglue benchmark wang et al 2019a for the first time in terms of macro average score 89 9 versus 89 8 and the ensemble deberta model sits atop the superglue leaderboard as of january 6 2021 out performing the human baseline by a decent margin 90 3 versus 89 8 ',\n",
       "   'title': 'DeBERTa: Decoding-enhanced BERT with Disentangled Attention'}}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory\n",
    "\n",
    "# Chains\n",
    "\n",
    "# Agent\n",
    "\n",
    "# (need to answer user input and look for resources based on the metadata returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQAWithSourcesChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    # chain_type=\"stuff\",\n",
    "    # document_prompt=,\n",
    "    # question_prompt=,\n",
    "    # combine_prompt=\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Search\",\n",
      "    \"action_input\": \"Some Question\"\n",
      "}\u001b[0m"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Document prompt requires documents to have metadata variables: ['source']. Received document with missing metadata: ['source'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m llm\u001b[39m=\u001b[39mChatOpenAI(temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m agent_chain \u001b[39m=\u001b[39m initialize_agent(tools, llm, agent\u001b[39m=\u001b[39mAgentType\u001b[39m.\u001b[39mCHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, memory\u001b[39m=\u001b[39mmemory)\n\u001b[0;32m---> 18\u001b[0m agent_chain\u001b[39m.\u001b[39;49mrun(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSome Question\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:445\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    441\u001b[0m         _output_key\n\u001b[1;32m    442\u001b[0m     ]\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    446\u001b[0m         _output_key\n\u001b[1;32m    447\u001b[0m     ]\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    450\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/agents/agent.py:987\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 987\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    988\u001b[0m         name_to_tool_map,\n\u001b[1;32m    989\u001b[0m         color_mapping,\n\u001b[1;32m    990\u001b[0m         inputs,\n\u001b[1;32m    991\u001b[0m         intermediate_steps,\n\u001b[1;32m    992\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    993\u001b[0m     )\n\u001b[1;32m    994\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    995\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m    996\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m    997\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/agents/agent.py:850\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    848\u001b[0m         tool_run_kwargs[\u001b[39m\"\u001b[39m\u001b[39mllm_prefix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m     \u001b[39m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m--> 850\u001b[0m     observation \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    851\u001b[0m         agent_action\u001b[39m.\u001b[39;49mtool_input,\n\u001b[1;32m    852\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    853\u001b[0m         color\u001b[39m=\u001b[39;49mcolor,\n\u001b[1;32m    854\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_run_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     tool_run_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/tools/base.py:320\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    319\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    321\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    322\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_end(\n\u001b[1;32m    323\u001b[0m         \u001b[39mstr\u001b[39m(observation), color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    324\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/tools/base.py:292\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    291\u001b[0m     observation \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 292\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39m*\u001b[39;49mtool_args, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs)\n\u001b[1;32m    293\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    294\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(\u001b[39m*\u001b[39mtool_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtool_kwargs)\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    296\u001b[0m \u001b[39mexcept\u001b[39;00m ToolException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    297\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_tool_error:\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/tools/base.py:444\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m new_argument_supported \u001b[39m=\u001b[39m signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    443\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\n\u001b[1;32m    445\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[1;32m    446\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    448\u001b[0m     )\n\u001b[1;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m new_argument_supported\n\u001b[1;32m    450\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    451\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/qa_with_sources/base.py:145\u001b[0m, in \u001b[0;36mBaseQAWithSourcesChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(inputs)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    146\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSOURCES:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, answer):\n\u001b[1;32m    149\u001b[0m     answer, sources \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSOURCES:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, answer)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:445\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    441\u001b[0m         _output_key\n\u001b[1;32m    442\u001b[0m     ]\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    446\u001b[0m         _output_key\n\u001b[1;32m    447\u001b[0m     ]\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    450\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:106\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    105\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m--> 106\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    107\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    109\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/map_reduce.py:221\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m question_result_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39moutput_key\n\u001b[1;32m    216\u001b[0m result_docs \u001b[39m=\u001b[39m [\n\u001b[1;32m    217\u001b[0m     Document(page_content\u001b[39m=\u001b[39mr[question_result_key], metadata\u001b[39m=\u001b[39mdocs[i]\u001b[39m.\u001b[39mmetadata)\n\u001b[1;32m    218\u001b[0m     \u001b[39m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(map_results)\n\u001b[1;32m    220\u001b[0m ]\n\u001b[0;32m--> 221\u001b[0m result, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce_documents_chain\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    222\u001b[0m     result_docs, token_max\u001b[39m=\u001b[39;49mtoken_max, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    223\u001b[0m )\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_intermediate_steps:\n\u001b[1;32m    225\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m [r[question_result_key] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m map_results]\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/reduce.py:195\u001b[0m, in \u001b[0;36mReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcombine_docs\u001b[39m(\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    175\u001b[0m     docs: List[Document],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    179\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m    180\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Combine multiple documents recursively.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[1;32m    182\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m        element returned is a dictionary of other keys to return.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     result_docs, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collapse(\n\u001b[1;32m    196\u001b[0m         docs, token_max\u001b[39m=\u001b[39;49mtoken_max, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_documents_chain\u001b[39m.\u001b[39mcombine_docs(\n\u001b[1;32m    199\u001b[0m         docs\u001b[39m=\u001b[39mresult_docs, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    200\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/reduce.py:240\u001b[0m, in \u001b[0;36mReduceDocumentsChain._collapse\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m result_docs \u001b[39m=\u001b[39m docs\n\u001b[1;32m    239\u001b[0m length_func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_documents_chain\u001b[39m.\u001b[39mprompt_length\n\u001b[0;32m--> 240\u001b[0m num_tokens \u001b[39m=\u001b[39m length_func(result_docs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_collapse_docs_func\u001b[39m(docs: List[Document], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collapse_chain\u001b[39m.\u001b[39mrun(\n\u001b[1;32m    244\u001b[0m         input_documents\u001b[39m=\u001b[39mdocs, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:145\u001b[0m, in \u001b[0;36mStuffDocumentsChain.prompt_length\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprompt_length\u001b[39m(\u001b[39mself\u001b[39m, docs: List[Document], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39mint\u001b[39m]:\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the prompt length given the documents passed in.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[39m    This can be used by a caller to determine whether passing in a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m        otherwise the length of the prompt in tokens.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_inputs(docs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    146\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mget_num_tokens(prompt)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:119\u001b[0m, in \u001b[0;36mStuffDocumentsChain._get_inputs\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct inputs from kwargs and docs.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mFormat and the join all the documents together into one input with name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m    dictionary of inputs to LLMChain\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# Format each document according to the prompt\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m doc_strings \u001b[39m=\u001b[39m [format_document(doc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocument_prompt) \u001b[39mfor\u001b[39;49;00m doc \u001b[39min\u001b[39;49;00m docs]\n\u001b[1;32m    120\u001b[0m \u001b[39m# Join the documents together to put them in the prompt.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m    122\u001b[0m     k: v\n\u001b[1;32m    123\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39minput_variables\n\u001b[1;32m    125\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:119\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct inputs from kwargs and docs.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mFormat and the join all the documents together into one input with name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m    dictionary of inputs to LLMChain\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# Format each document according to the prompt\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m doc_strings \u001b[39m=\u001b[39m [format_document(doc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocument_prompt) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[1;32m    120\u001b[0m \u001b[39m# Join the documents together to put them in the prompt.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m    122\u001b[0m     k: v\n\u001b[1;32m    123\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39minput_variables\n\u001b[1;32m    125\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/schema/prompt_template.py:183\u001b[0m, in \u001b[0;36mformat_document\u001b[0;34m(doc, prompt)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_metadata) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    180\u001b[0m     required_metadata \u001b[39m=\u001b[39m [\n\u001b[1;32m    181\u001b[0m         iv \u001b[39mfor\u001b[39;00m iv \u001b[39min\u001b[39;00m prompt\u001b[39m.\u001b[39minput_variables \u001b[39mif\u001b[39;00m iv \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpage_content\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     ]\n\u001b[0;32m--> 183\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDocument prompt requires documents to have metadata variables: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrequired_metadata\u001b[39m}\u001b[39;00m\u001b[39m. Received document with missing metadata: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(missing_metadata)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m document_info \u001b[39m=\u001b[39m {k: base_info[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m prompt\u001b[39m.\u001b[39minput_variables}\n\u001b[1;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m prompt\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdocument_info)\n",
      "\u001b[0;31mValueError\u001b[0m: Document prompt requires documents to have metadata variables: ['source']. Received document with missing metadata: ['source']."
     ]
    }
   ],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        name = \"Search\",\n",
    "        func=qa.__call__, #chain doesn't work anymore because of some inspection issue and there is no call function\n",
    "        coroutine=qa.acall, #if you want to use async\n",
    "        description=\"useful to answer factual questions\"\n",
    "    ),\n",
    "]\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "llm=ChatOpenAI(temperature=0)\n",
    "agent_chain = initialize_agent(tools, llm, agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose=True, memory=memory)\n",
    "agent_chain.run(input=\"Some Question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"Some follow-up Question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Document prompt requires documents to have metadata variables: ['source']. Received document with missing metadata: ['source'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qa\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(query)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/qa_with_sources/base.py:145\u001b[0m, in \u001b[0;36mBaseQAWithSourcesChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(inputs)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    146\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39msearch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSOURCES:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, answer):\n\u001b[1;32m    149\u001b[0m     answer, sources \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSOURCES:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, answer)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:445\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    441\u001b[0m         _output_key\n\u001b[1;32m    442\u001b[0m     ]\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    446\u001b[0m         _output_key\n\u001b[1;32m    447\u001b[0m     ]\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    450\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:106\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    105\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m--> 106\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    107\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    109\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/map_reduce.py:221\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m question_result_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39moutput_key\n\u001b[1;32m    216\u001b[0m result_docs \u001b[39m=\u001b[39m [\n\u001b[1;32m    217\u001b[0m     Document(page_content\u001b[39m=\u001b[39mr[question_result_key], metadata\u001b[39m=\u001b[39mdocs[i]\u001b[39m.\u001b[39mmetadata)\n\u001b[1;32m    218\u001b[0m     \u001b[39m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(map_results)\n\u001b[1;32m    220\u001b[0m ]\n\u001b[0;32m--> 221\u001b[0m result, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduce_documents_chain\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    222\u001b[0m     result_docs, token_max\u001b[39m=\u001b[39;49mtoken_max, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    223\u001b[0m )\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_intermediate_steps:\n\u001b[1;32m    225\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m [r[question_result_key] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m map_results]\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/reduce.py:195\u001b[0m, in \u001b[0;36mReduceDocumentsChain.combine_docs\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcombine_docs\u001b[39m(\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    175\u001b[0m     docs: List[Document],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    179\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m]:\n\u001b[1;32m    180\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Combine multiple documents recursively.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \n\u001b[1;32m    182\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m        element returned is a dictionary of other keys to return.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     result_docs, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collapse(\n\u001b[1;32m    196\u001b[0m         docs, token_max\u001b[39m=\u001b[39;49mtoken_max, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_documents_chain\u001b[39m.\u001b[39mcombine_docs(\n\u001b[1;32m    199\u001b[0m         docs\u001b[39m=\u001b[39mresult_docs, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    200\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/reduce.py:240\u001b[0m, in \u001b[0;36mReduceDocumentsChain._collapse\u001b[0;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m result_docs \u001b[39m=\u001b[39m docs\n\u001b[1;32m    239\u001b[0m length_func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_documents_chain\u001b[39m.\u001b[39mprompt_length\n\u001b[0;32m--> 240\u001b[0m num_tokens \u001b[39m=\u001b[39m length_func(result_docs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_collapse_docs_func\u001b[39m(docs: List[Document], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collapse_chain\u001b[39m.\u001b[39mrun(\n\u001b[1;32m    244\u001b[0m         input_documents\u001b[39m=\u001b[39mdocs, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:145\u001b[0m, in \u001b[0;36mStuffDocumentsChain.prompt_length\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprompt_length\u001b[39m(\u001b[39mself\u001b[39m, docs: List[Document], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39mint\u001b[39m]:\n\u001b[1;32m    130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the prompt length given the documents passed in.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[1;32m    132\u001b[0m \u001b[39m    This can be used by a caller to determine whether passing in a list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m        otherwise the length of the prompt in tokens.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_inputs(docs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    146\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mget_num_tokens(prompt)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:119\u001b[0m, in \u001b[0;36mStuffDocumentsChain._get_inputs\u001b[0;34m(self, docs, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct inputs from kwargs and docs.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mFormat and the join all the documents together into one input with name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m    dictionary of inputs to LLMChain\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# Format each document according to the prompt\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m doc_strings \u001b[39m=\u001b[39m [format_document(doc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocument_prompt) \u001b[39mfor\u001b[39;49;00m doc \u001b[39min\u001b[39;49;00m docs]\n\u001b[1;32m    120\u001b[0m \u001b[39m# Join the documents together to put them in the prompt.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m    122\u001b[0m     k: v\n\u001b[1;32m    123\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39minput_variables\n\u001b[1;32m    125\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:119\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Construct inputs from kwargs and docs.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mFormat and the join all the documents together into one input with name\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m    dictionary of inputs to LLMChain\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# Format each document according to the prompt\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m doc_strings \u001b[39m=\u001b[39m [format_document(doc, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdocument_prompt) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m docs]\n\u001b[1;32m    120\u001b[0m \u001b[39m# Join the documents together to put them in the prompt.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m    122\u001b[0m     k: v\n\u001b[1;32m    123\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39minput_variables\n\u001b[1;32m    125\u001b[0m }\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/schema/prompt_template.py:183\u001b[0m, in \u001b[0;36mformat_document\u001b[0;34m(doc, prompt)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_metadata) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    180\u001b[0m     required_metadata \u001b[39m=\u001b[39m [\n\u001b[1;32m    181\u001b[0m         iv \u001b[39mfor\u001b[39;00m iv \u001b[39min\u001b[39;00m prompt\u001b[39m.\u001b[39minput_variables \u001b[39mif\u001b[39;00m iv \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpage_content\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     ]\n\u001b[0;32m--> 183\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDocument prompt requires documents to have metadata variables: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrequired_metadata\u001b[39m}\u001b[39;00m\u001b[39m. Received document with missing metadata: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(missing_metadata)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    188\u001b[0m document_info \u001b[39m=\u001b[39m {k: base_info[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m prompt\u001b[39m.\u001b[39minput_variables}\n\u001b[1;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m prompt\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdocument_info)\n",
      "\u001b[0;31mValueError\u001b[0m: Document prompt requires documents to have metadata variables: ['source']. Received document with missing metadata: ['source']."
     ]
    }
   ],
   "source": [
    "qa.__call__(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
