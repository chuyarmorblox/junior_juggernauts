{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Union\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.agents import initialize_agent, Tool, AgentExecutor, AgentType, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.tools import YouTubeSearchTool\n",
    "from langchain import SerpAPIWrapper, PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "SERPAPI_API_KEY = os.environ['SERPAPI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'text-embedding-ada-002'\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.load_local(\"arxiv_vectorstore\", embeddings=embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_chunks_tool = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever()\n",
    ")\n",
    "search_tool = SerpAPIWrapper(serpapi_api_key=SERPAPI_API_KEY)\n",
    "youtube_tool = YouTubeSearchTool()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"FAISS QA System\",\n",
    "        func=papers_chunks_tool.run,\n",
    "        description=\"useful to answer questions about LLMs and artificial intelligence. use this more than the other tool if the question is related to artificial intelligence and/or LLMS\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search_tool.run,\n",
    "        description=\"useful for when you need to look for some resources such as web articles and educational courses\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Youtube Search\",\n",
    "        func=youtube_tool.run,\n",
    "        description=\"useful for finding educational videos\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Complete the objective as best you can. You are an AI agent designed to help users study the topic of LLMs. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "After finding the answer to the original question, search for a related web article.\n",
    "After finding the web article, search for one related Youtube video's url link. Output the original question's answer and the Youtube urls.\n",
    "After having both the answer to the question and the additional resources, output the answer and the resources.\n",
    "\n",
    "These were previous tasks you completed:\n",
    "\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {user_input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"user_input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names,\n",
    "    # verbose=True,\n",
    "    return_intermediate_steps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: LLMs are a topic related to artificial intelligence and language models. I should use the FAISS QA System to get a detailed answer.\n",
      "Action: FAISS QA System\n",
      "Action Input: \"What are LLMs?\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m LLMs are large language models, which are deep neural networks used to generate natural language. They are used for tasks such as natural language processing, text generation, and language understanding.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI have the answer to the original question. Now I need to search for a related web article.\n",
      "Action: Search\n",
      "Action Input: \"LLMs explained\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3mLarge language models (LLMs) are recent advances in deep learning models to work on human languages. Some great use case of LLMs has been demonstrated. A large language model is a trained deep-learning model that understands and generates text in a human-like fashion.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI have found a web article related to LLMs. Now I need to search for a related Youtube video.\n",
      "Action: Youtube Search\n",
      "Action Input: \"LLMs explained\"\u001b[0m\n",
      "\n",
      "Observation:\u001b[38;5;200m\u001b[1;3m['/watch?v=zizonToFXDs&pp=ygUOTExNcyBleHBsYWluZWQ%3D', '/watch?v=iR2O2GPbB0E&pp=ygUOTExNcyBleHBsYWluZWQ%3D']\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI have found a Youtube video related to LLMs. Now I have the answer to the original question and the additional resources.\n",
      "\n",
      "Final Answer: LLMs are large language models, which are deep neural networks used to generate natural language. They are used for tasks such as natural language processing, text generation, and language understanding.\n",
      "\n",
      "Web Article: \"LLMs explained\" - Large language models (LLMs) are recent advances in deep learning models to work on human languages. Some great use case of LLMs has been demonstrated. A large language model is a trained deep-learning model that understands and generates text in a human-like fashion.\n",
      "\n",
      "Youtube Videos:\n",
      "1. [LLMs Explained](https://www.youtube.com/watch?v=zizonToFXDs&pp=ygUOTExNcyBleHBsYWluZWQ%3D)\n",
      "2. [Understanding LLMs](https://www.youtube.com/watch?v=iR2O2GPbB0E&pp=ygUOTExNcyBleHBsYWluZWQ%3D)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer_ = agent_executor.run(\"What are LLMs?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLMs are large language models, which are deep neural networks used to generate natural language. They are used for tasks such as natural language processing, text generation, and language understanding.\\n\\nWeb Article: \"LLMs explained\" - Large language models (LLMs) are recent advances in deep learning models to work on human languages. Some great use case of LLMs has been demonstrated. A large language model is a trained deep-learning model that understands and generates text in a human-like fashion.\\n\\nYoutube Videos:\\n1. [LLMs Explained](https://www.youtube.com/watch?v=zizonToFXDs&pp=ygUOTExNcyBleHBsYWluZWQ%3D)\\n2. [Understanding LLMs](https://www.youtube.com/watch?v=iR2O2GPbB0E&pp=ygUOTExNcyBleHBsYWluZWQ%3D)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
