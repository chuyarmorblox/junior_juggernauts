{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = arxiv.Search(\n",
    "  query=\"cat:cs.CL\",\n",
    "  max_results=1000,\n",
    "  sort_by=arxiv.SortCriterion.Relevance,\n",
    "  sort_order=arxiv.SortOrder.Descending\n",
    ")\n",
    "\n",
    "search2 = arxiv.Search(\n",
    "  query=\"cat:cs.CL\",\n",
    "  max_results=2000,\n",
    "  sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    "  sort_order=arxiv.SortOrder.Descending\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = list(search.results()) + list(search2.results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arxiv.Result(entry_id='http://arxiv.org/abs/cs/9809020v1', updated=datetime.datetime(1998, 9, 15, 23, 49, 32, tzinfo=datetime.timezone.utc), published=datetime.datetime(1998, 9, 15, 23, 49, 32, tzinfo=datetime.timezone.utc), title='Linear Segmentation and Segment Significance', authors=[arxiv.Result.Author('Min-Yen Kan'), arxiv.Result.Author('Judith L. Klavans'), arxiv.Result.Author('Kathleen R. McKeown')], summary='We present a new method for discovering a segmental discourse structure of a\\ndocument while categorizing segment function. We demonstrate how retrieval of\\nnoun phrases and pronominal forms, along with a zero-sum weighting scheme,\\ndetermines topicalized segmentation. Futhermore, we use term distribution to\\naid in identifying the role that the segment performs in the document. Finally,\\nwe present results of evaluation in terms of precision and recall which surpass\\nearlier approaches.', comment='9 pages, US Letter, 4 figures. Software License can be found at\\n  http://www.cs.columbia.edu/nlp/licenses/segmenterLicenseDownload.html', journal_ref='Proceedings of 6th International Workshop of Very Large Corpora\\n  (WVLC-6), Montreal, Quebec, Canada: Aug. 1998. pp. 197-205', doi=None, primary_category='cs.CL', categories=['cs.CL', 'I.2.7'], links=[arxiv.Result.Link('http://arxiv.org/abs/cs/9809020v1', title=None, rel='alternate', content_type=None), arxiv.Result.Link('http://arxiv.org/pdf/cs/9809020v1', title='pdf', rel='related', content_type=None)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 pages, US Letter, 4 figures. Software License can be found at\\n  http://www.cs.columbia.edu/nlp/licenses/segmenterLicenseDownload.html'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[0].comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': [arxiv.Result.Author('Min-Yen Kan'),\n",
       "  arxiv.Result.Author('Judith L. Klavans'),\n",
       "  arxiv.Result.Author('Kathleen R. McKeown')],\n",
       " 'categories': ['cs.CL', 'I.2.7'],\n",
       " 'comment': '9 pages, US Letter, 4 figures. Software License can be found at\\n  http://www.cs.columbia.edu/nlp/licenses/segmenterLicenseDownload.html',\n",
       " 'doi': None,\n",
       " 'entry_id': 'http://arxiv.org/abs/cs/9809020v1',\n",
       " 'journal_ref': 'Proceedings of 6th International Workshop of Very Large Corpora\\n  (WVLC-6), Montreal, Quebec, Canada: Aug. 1998. pp. 197-205',\n",
       " 'pdf_url': 'http://arxiv.org/pdf/cs/9809020v1',\n",
       " 'primary_category': 'cs.CL',\n",
       " 'published': datetime.datetime(1998, 9, 15, 23, 49, 32, tzinfo=datetime.timezone.utc),\n",
       " 'summary': 'We present a new method for discovering a segmental discourse structure of a\\ndocument while categorizing segment function. We demonstrate how retrieval of\\nnoun phrases and pronominal forms, along with a zero-sum weighting scheme,\\ndetermines topicalized segmentation. Futhermore, we use term distribution to\\naid in identifying the role that the segment performs in the document. Finally,\\nwe present results of evaluation in terms of precision and recall which surpass\\nearlier approaches.',\n",
       " 'title': 'Linear Segmentation and Segment Significance',\n",
       " 'updated': datetime.datetime(1998, 9, 15, 23, 49, 32, tzinfo=datetime.timezone.utc)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'authors': papers[0].authors,\n",
    "    'categories': papers[0].categories,\n",
    "    'comment': papers[0].comment,\n",
    "    'doi': papers[0].doi,\n",
    "    'entry_id': papers[0].entry_id,\n",
    "    'journal_ref': papers[0].journal_ref,\n",
    "    'pdf_url': papers[0].pdf_url,\n",
    "    'primary_category': papers[0].primary_category,\n",
    "    'published': papers[0].published,\n",
    "    'summary': papers[0].summary,\n",
    "    'title': papers[0].title,\n",
    "    'updated': papers[0].updated\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>comment</th>\n",
       "      <th>doi</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Min-Yen Kan, Judith L. Klavans, Kathleen R. M...</td>\n",
       "      <td>[cs.CL, I.2.7]</td>\n",
       "      <td>9 pages, US Letter, 4 figures. Software Licens...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809020v1</td>\n",
       "      <td>Proceedings of 6th International Workshop of V...</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809020</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-15 23:49:32+00:00</td>\n",
       "      <td>We present a new method for discovering a segm...</td>\n",
       "      <td>Linear Segmentation and Segment Significance</td>\n",
       "      <td>1998-09-15 23:49:32+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Bernd Ludwig, Guenther Goerz, Heinrich Niemann]</td>\n",
       "      <td>[cs.CL, H.5.2]</td>\n",
       "      <td>17 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809022v1</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809022</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-17 11:10:14+00:00</td>\n",
       "      <td>We outline how utterances in dialogs can be in...</td>\n",
       "      <td>Modelling Users, Intentions, and Structure in ...</td>\n",
       "      <td>1998-09-17 11:10:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[XTAG Research Group]</td>\n",
       "      <td>[cs.CL, I.2.7; D.3.1]</td>\n",
       "      <td>310 pages, 181 Postscript figures, uses 11pt, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809024v2</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809024</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-18 00:33:47+00:00</td>\n",
       "      <td>This document describes a sizable grammar of E...</td>\n",
       "      <td>A Lexicalized Tree Adjoining Grammar for English</td>\n",
       "      <td>1998-09-18 02:49:22+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Mark-Jan Nederhof, Anoop Sarkar, Giorgio Satta]</td>\n",
       "      <td>[cs.CL, I.2.7; D.3.1]</td>\n",
       "      <td>7 pages, 2 Postscript figures, uses colacl.sty...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809026v1</td>\n",
       "      <td>In Proceedings of COLING-ACL '98 (Montreal)</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809026</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-18 03:45:45+00:00</td>\n",
       "      <td>Language models for speech recognition typical...</td>\n",
       "      <td>Prefix Probabilities from Stochastic Tree Adjo...</td>\n",
       "      <td>1998-09-18 03:45:45+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Anoop Sarkar]</td>\n",
       "      <td>[cs.CL, I.2.7; D.3.1]</td>\n",
       "      <td>7 pages, 4 Postscript figures, uses colacl.sty...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809027v1</td>\n",
       "      <td>In Proceedings of COLING-ACL '98 (Montreal)</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809027</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-18 03:58:57+00:00</td>\n",
       "      <td>Much of the power of probabilistic methods in ...</td>\n",
       "      <td>Conditions on Consistency of Probabilistic Tre...</td>\n",
       "      <td>1998-09-18 03:58:57+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors             categories  \\\n",
       "0  [Min-Yen Kan, Judith L. Klavans, Kathleen R. M...         [cs.CL, I.2.7]   \n",
       "1   [Bernd Ludwig, Guenther Goerz, Heinrich Niemann]         [cs.CL, H.5.2]   \n",
       "2                              [XTAG Research Group]  [cs.CL, I.2.7; D.3.1]   \n",
       "3   [Mark-Jan Nederhof, Anoop Sarkar, Giorgio Satta]  [cs.CL, I.2.7; D.3.1]   \n",
       "4                                     [Anoop Sarkar]  [cs.CL, I.2.7; D.3.1]   \n",
       "\n",
       "                                             comment   doi  \\\n",
       "0  9 pages, US Letter, 4 figures. Software Licens...  None   \n",
       "1                                           17 pages  None   \n",
       "2  310 pages, 181 Postscript figures, uses 11pt, ...  None   \n",
       "3  7 pages, 2 Postscript figures, uses colacl.sty...  None   \n",
       "4  7 pages, 4 Postscript figures, uses colacl.sty...  None   \n",
       "\n",
       "                            entry_id  \\\n",
       "0  http://arxiv.org/abs/cs/9809020v1   \n",
       "1  http://arxiv.org/abs/cs/9809022v1   \n",
       "2  http://arxiv.org/abs/cs/9809024v2   \n",
       "3  http://arxiv.org/abs/cs/9809026v1   \n",
       "4  http://arxiv.org/abs/cs/9809027v1   \n",
       "\n",
       "                                         journal_ref  \\\n",
       "0  Proceedings of 6th International Workshop of V...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3        In Proceedings of COLING-ACL '98 (Montreal)   \n",
       "4        In Proceedings of COLING-ACL '98 (Montreal)   \n",
       "\n",
       "                           pdf_url primary_category                 published  \\\n",
       "0  http://arxiv.org/pdf/cs/9809020            cs.CL 1998-09-15 23:49:32+00:00   \n",
       "1  http://arxiv.org/pdf/cs/9809022            cs.CL 1998-09-17 11:10:14+00:00   \n",
       "2  http://arxiv.org/pdf/cs/9809024            cs.CL 1998-09-18 00:33:47+00:00   \n",
       "3  http://arxiv.org/pdf/cs/9809026            cs.CL 1998-09-18 03:45:45+00:00   \n",
       "4  http://arxiv.org/pdf/cs/9809027            cs.CL 1998-09-18 03:58:57+00:00   \n",
       "\n",
       "                                             summary  \\\n",
       "0  We present a new method for discovering a segm...   \n",
       "1  We outline how utterances in dialogs can be in...   \n",
       "2  This document describes a sizable grammar of E...   \n",
       "3  Language models for speech recognition typical...   \n",
       "4  Much of the power of probabilistic methods in ...   \n",
       "\n",
       "                                               title                   updated  \n",
       "0       Linear Segmentation and Segment Significance 1998-09-15 23:49:32+00:00  \n",
       "1  Modelling Users, Intentions, and Structure in ... 1998-09-17 11:10:14+00:00  \n",
       "2   A Lexicalized Tree Adjoining Grammar for English 1998-09-18 02:49:22+00:00  \n",
       "3  Prefix Probabilities from Stochastic Tree Adjo... 1998-09-18 03:45:45+00:00  \n",
       "4  Conditions on Consistency of Probabilistic Tre... 1998-09-18 03:58:57+00:00  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for result in papers:\n",
    "    result.pdf_url = re.sub(r'v\\d+$', '', result.pdf_url)\n",
    "\n",
    "    dataset.append({\n",
    "        'authors': result.authors,\n",
    "        'categories': result.categories,\n",
    "        'comment': result.comment,\n",
    "        'doi': result.doi,\n",
    "        'entry_id': result.entry_id,\n",
    "        'journal_ref': result.journal_ref,\n",
    "        'pdf_url': result.pdf_url,\n",
    "        'primary_category': result.primary_category,\n",
    "        'published': result.published,\n",
    "        'summary': result.summary,\n",
    "        'title': result.title,\n",
    "        'updated': result.updated\n",
    "    })\n",
    "\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_json('dataset.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://export.arxiv.org/pdf/2212.08897'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https://export.\"+\"http://arxiv.org/pdf/2212.08897\".split(\"://\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "pdf_url = \"http://export.arxiv.org/pdf/2212.08897\"\n",
    "\n",
    "r = requests.get(pdf_url)\n",
    "with open(f\"temp.pdf\", \"wb\") as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "text = []\n",
    "\n",
    "with open(\"temp.pdf\", \"rb\") as file:\n",
    "    pdf = PyPDF2.PdfReader(file)\n",
    "    for page in range(len(pdf.pages)):\n",
    "        page_obj = pdf.pages[page]\n",
    "        text.append(page_obj.extract_text())\n",
    "\n",
    "text = \"\\n\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PyPDF2' has no attribute 'PdfReadError'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPdfReadError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtemp.pdf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m---> 12\u001b[0m     pdf \u001b[39m=\u001b[39m PyPDF2\u001b[39m.\u001b[39;49mPdfReader(file)\n\u001b[1;32m     13\u001b[0m     \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(pdf\u001b[39m.\u001b[39mpages)):\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/PyPDF2/_reader.py:319\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[0;34m(self, stream, strict, password)\u001b[0m\n\u001b[1;32m    318\u001b[0m         stream \u001b[39m=\u001b[39m BytesIO(fh\u001b[39m.\u001b[39mread())\n\u001b[0;32m--> 319\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(stream)\n\u001b[1;32m    320\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m stream\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/PyPDF2/_reader.py:1415\u001b[0m, in \u001b[0;36mPdfReader.read\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_basic_validation(stream)\n\u001b[0;32m-> 1415\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_eof_marker(stream)\n\u001b[1;32m   1416\u001b[0m startxref \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_startxref_pos(stream)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.11/site-packages/PyPDF2/_reader.py:1471\u001b[0m, in \u001b[0;36mPdfReader._find_eof_marker\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[39mif\u001b[39;00m stream\u001b[39m.\u001b[39mtell() \u001b[39m<\u001b[39m last_mb:\n\u001b[0;32m-> 1471\u001b[0m     \u001b[39mraise\u001b[39;00m PdfReadError(\u001b[39m\"\u001b[39m\u001b[39mEOF marker not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1472\u001b[0m line \u001b[39m=\u001b[39m read_previous_line(stream)\n",
      "\u001b[0;31mPdfReadError\u001b[0m: EOF marker not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m             page_obj \u001b[39m=\u001b[39m pdf\u001b[39m.\u001b[39mpages[page]\n\u001b[1;32m     15\u001b[0m             text\u001b[39m.\u001b[39mappend(page_obj\u001b[39m.\u001b[39mextract_text())\n\u001b[0;32m---> 16\u001b[0m \u001b[39mexcept\u001b[39;00m PyPDF2\u001b[39m.\u001b[39;49mPdfReadError:\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt read file from url: \u001b[39m\u001b[39m{\u001b[39;00mpdf_url\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     text \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'PyPDF2' has no attribute 'PdfReadError'"
     ]
    }
   ],
   "source": [
    "# all_text = []\n",
    "# for pdf_url in dataset['pdf_url']:\n",
    "#     pdf_url = \"https://export.\"+pdf_url.split(\"://\")[-1]\n",
    "#     text = []\n",
    "\n",
    "#     r = requests.get(pdf_url)\n",
    "#     with open(f\"temp.pdf\", \"wb\") as f:\n",
    "#         f.write(r.content)\n",
    "\n",
    "#     try:\n",
    "#         with open(\"temp.pdf\", \"rb\") as file:\n",
    "#             pdf = PyPDF2.PdfReader(file)\n",
    "#             for page in range(len(pdf.pages)):\n",
    "#                 page_obj = pdf.pages[page]\n",
    "#                 text.append(page_obj.extract_text())\n",
    "#     except PdfReadError:\n",
    "#         print(f\"Couldn't read file from url: {pdf_url}\")\n",
    "#         text = []\n",
    "\n",
    "#     text = \"\\n\".join(text)\n",
    "\n",
    "#     all_text.append(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "all_text = []\n",
    "for pdf_url in dataset['pdf_url']:\n",
    "    pdf_url = \"https://export.\"+pdf_url.split(\"://\")[-1]\n",
    "    text = ''\n",
    "\n",
    "    r = requests.get(pdf_url)\n",
    "    with open(\"temp.pdf\", \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    try:\n",
    "        text = extract_text(\"temp.pdf\")\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't read file from url: {pdf_url}, due to error: {str(e)}\")\n",
    "\n",
    "    all_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = all_text\n",
    "dataset.to_json(\"arxiv_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>comment</th>\n",
       "      <th>doi</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>updated</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Min-Yen Kan, Judith L. Klavans, Kathleen R. M...</td>\n",
       "      <td>[cs.CL, I.2.7]</td>\n",
       "      <td>9 pages, US Letter, 4 figures. Software Licens...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809020v1</td>\n",
       "      <td>Proceedings of 6th International Workshop of V...</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809020</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-15 23:49:32+00:00</td>\n",
       "      <td>We present a new method for discovering a segm...</td>\n",
       "      <td>Linear Segmentation and Segment Significance</td>\n",
       "      <td>1998-09-15 23:49:32+00:00</td>\n",
       "      <td>Linear Segmentation and Segment Significance\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Bernd Ludwig, Guenther Goerz, Heinrich Niemann]</td>\n",
       "      <td>[cs.CL, H.5.2]</td>\n",
       "      <td>17 pages</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809022v1</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809022</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-17 11:10:14+00:00</td>\n",
       "      <td>We outline how utterances in dialogs can be in...</td>\n",
       "      <td>Modelling Users, Intentions, and Structure in ...</td>\n",
       "      <td>1998-09-17 11:10:14+00:00</td>\n",
       "      <td>8\\n9\\n9\\n1\\n\\np\\ne\\nS\\n7\\n1\\n\\n]\\nL\\nC\\n.\\ns\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[XTAG Research Group]</td>\n",
       "      <td>[cs.CL, I.2.7; D.3.1]</td>\n",
       "      <td>310 pages, 181 Postscript figures, uses 11pt, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809024v2</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809024</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-18 00:33:47+00:00</td>\n",
       "      <td>This document describes a sizable grammar of E...</td>\n",
       "      <td>A Lexicalized Tree Adjoining Grammar for English</td>\n",
       "      <td>1998-09-18 02:49:22+00:00</td>\n",
       "      <td>8\\n9\\n9\\n1\\n\\np\\ne\\nS\\n8\\n1\\n\\n]\\nL\\nC\\n.\\ns\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Mark-Jan Nederhof, Anoop Sarkar, Giorgio Satta]</td>\n",
       "      <td>[cs.CL, I.2.7; D.3.1]</td>\n",
       "      <td>7 pages, 2 Postscript figures, uses colacl.sty...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809026v1</td>\n",
       "      <td>In Proceedings of COLING-ACL '98 (Montreal)</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809026</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-18 03:45:45+00:00</td>\n",
       "      <td>Language models for speech recognition typical...</td>\n",
       "      <td>Prefix Probabilities from Stochastic Tree Adjo...</td>\n",
       "      <td>1998-09-18 03:45:45+00:00</td>\n",
       "      <td>8\\n9\\n9\\n1\\n\\np\\ne\\nS\\n8\\n1\\n\\n]\\nL\\nC\\n.\\ns\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Anoop Sarkar]</td>\n",
       "      <td>[cs.CL, I.2.7; D.3.1]</td>\n",
       "      <td>7 pages, 4 Postscript figures, uses colacl.sty...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/cs/9809027v1</td>\n",
       "      <td>In Proceedings of COLING-ACL '98 (Montreal)</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9809027</td>\n",
       "      <td>cs.CL</td>\n",
       "      <td>1998-09-18 03:58:57+00:00</td>\n",
       "      <td>Much of the power of probabilistic methods in ...</td>\n",
       "      <td>Conditions on Consistency of Probabilistic Tre...</td>\n",
       "      <td>1998-09-18 03:58:57+00:00</td>\n",
       "      <td>8\\n9\\n9\\n1\\n\\np\\ne\\nS\\n8\\n1\\n\\n]\\nL\\nC\\n.\\ns\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors             categories  \\\n",
       "0  [Min-Yen Kan, Judith L. Klavans, Kathleen R. M...         [cs.CL, I.2.7]   \n",
       "1   [Bernd Ludwig, Guenther Goerz, Heinrich Niemann]         [cs.CL, H.5.2]   \n",
       "2                              [XTAG Research Group]  [cs.CL, I.2.7; D.3.1]   \n",
       "3   [Mark-Jan Nederhof, Anoop Sarkar, Giorgio Satta]  [cs.CL, I.2.7; D.3.1]   \n",
       "4                                     [Anoop Sarkar]  [cs.CL, I.2.7; D.3.1]   \n",
       "\n",
       "                                             comment   doi  \\\n",
       "0  9 pages, US Letter, 4 figures. Software Licens...  None   \n",
       "1                                           17 pages  None   \n",
       "2  310 pages, 181 Postscript figures, uses 11pt, ...  None   \n",
       "3  7 pages, 2 Postscript figures, uses colacl.sty...  None   \n",
       "4  7 pages, 4 Postscript figures, uses colacl.sty...  None   \n",
       "\n",
       "                            entry_id  \\\n",
       "0  http://arxiv.org/abs/cs/9809020v1   \n",
       "1  http://arxiv.org/abs/cs/9809022v1   \n",
       "2  http://arxiv.org/abs/cs/9809024v2   \n",
       "3  http://arxiv.org/abs/cs/9809026v1   \n",
       "4  http://arxiv.org/abs/cs/9809027v1   \n",
       "\n",
       "                                         journal_ref  \\\n",
       "0  Proceedings of 6th International Workshop of V...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3        In Proceedings of COLING-ACL '98 (Montreal)   \n",
       "4        In Proceedings of COLING-ACL '98 (Montreal)   \n",
       "\n",
       "                           pdf_url primary_category                 published  \\\n",
       "0  http://arxiv.org/pdf/cs/9809020            cs.CL 1998-09-15 23:49:32+00:00   \n",
       "1  http://arxiv.org/pdf/cs/9809022            cs.CL 1998-09-17 11:10:14+00:00   \n",
       "2  http://arxiv.org/pdf/cs/9809024            cs.CL 1998-09-18 00:33:47+00:00   \n",
       "3  http://arxiv.org/pdf/cs/9809026            cs.CL 1998-09-18 03:45:45+00:00   \n",
       "4  http://arxiv.org/pdf/cs/9809027            cs.CL 1998-09-18 03:58:57+00:00   \n",
       "\n",
       "                                             summary  \\\n",
       "0  We present a new method for discovering a segm...   \n",
       "1  We outline how utterances in dialogs can be in...   \n",
       "2  This document describes a sizable grammar of E...   \n",
       "3  Language models for speech recognition typical...   \n",
       "4  Much of the power of probabilistic methods in ...   \n",
       "\n",
       "                                               title  \\\n",
       "0       Linear Segmentation and Segment Significance   \n",
       "1  Modelling Users, Intentions, and Structure in ...   \n",
       "2   A Lexicalized Tree Adjoining Grammar for English   \n",
       "3  Prefix Probabilities from Stochastic Tree Adjo...   \n",
       "4  Conditions on Consistency of Probabilistic Tre...   \n",
       "\n",
       "                    updated                                               text  \n",
       "0 1998-09-15 23:49:32+00:00  Linear Segmentation and Segment Significance\\n...  \n",
       "1 1998-09-17 11:10:14+00:00  8\\n9\\n9\\n1\\n\\np\\ne\\nS\\n7\\n1\\n\\n]\\nL\\nC\\n.\\ns\\n...  \n",
       "2 1998-09-18 02:49:22+00:00  8\\n9\\n9\\n1\\n\\np\\ne\\nS\\n8\\n1\\n\\n]\\nL\\nC\\n.\\ns\\n...  \n",
       "3 1998-09-18 03:45:45+00:00  8\\n9\\n9\\n1\\n\\np\\ne\\nS\\n8\\n1\\n\\n]\\nL\\nC\\n.\\ns\\n...  \n",
       "4 1998-09-18 03:58:57+00:00  8\\n9\\n9\\n1\\n\\np\\ne\\nS\\n8\\n1\\n\\n]\\nL\\nC\\n.\\ns\\n...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 empty strings in the text column.\n",
      "There are 100 empty strings or strings containing only whitespace in the text column.\n"
     ]
    }
   ],
   "source": [
    "empty_strings = (dataset['text'] == '').sum()\n",
    "print(f'There are {empty_strings} empty strings in the text column.')\n",
    "\n",
    "empty_or_whitespace_strings = (dataset['text'].str.strip() == '').sum()\n",
    "print(f'There are {empty_or_whitespace_strings} empty strings or strings containing only whitespace in the text column.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDITIONAL PAPERS (MANUALLY SELECTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_paper_ids = [\n",
    "    \"2201.03545\", \"2103.14030\", \"2010.11929\", \"2306.01128\", \"2305.05176\", \"2306.03078\", \"2305.14314\", \"2106.09685\", \"2303.09752\",\n",
    "    \"1911.02150\", \"2112.05682\", \"2205.14135\", \"2007.14062\", \"1904.10509\", \"2007.00072\", \"2001.08361\", \"2307.02486v1\", \"2305.03047\",\n",
    "    \"2305.06161v1\", \"2107.03374v2\", \"2305.15334\", \"2212.10560\", \"2305.18290\", \"2302.07842\", \"2302.04761\", \"2112.09332\", \"2206.07682\",\n",
    "    \"2302.14045\", \"2306.02707\", \"2302.13971\", \"2204.02311\", \"2210.11416\", \"2110.08207\", \"1910.10683\", \"2203.02155\", \"1706.03741\",\n",
    "    \"2305.19234\", \"2305.17126\", \"2305.10601\", \"2210.03629\", \"2302.00923\", \"2005.14165v2\", \"2006.03654\", \"2003.10555\", \"1906.08237\",\n",
    "    \"2002.10957\", \"1909.10351\", \"1910.01108\", \"1909.11942v1\", \"1907.11692\", \"1810.04805\", \"2006.16362\", \"2207.09238\", \"2208.06980\",\n",
    "    \"1706.03762\", \"1310.4546v1\", \"2303.18223\"\n",
    "]\n",
    "len(add_paper_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "search3 = arxiv.Search(\n",
    "  id_list=add_paper_ids,\n",
    ")\n",
    "papers_add = list(search3.results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'authors': [arxiv.Result.Author('Jacob Devlin'),\n",
       "  arxiv.Result.Author('Ming-Wei Chang'),\n",
       "  arxiv.Result.Author('Kenton Lee'),\n",
       "  arxiv.Result.Author('Kristina Toutanova')],\n",
       " 'categories': ['cs.CL'],\n",
       " 'comment': None,\n",
       " 'doi': None,\n",
       " 'entry_id': 'http://arxiv.org/abs/1810.04805v2',\n",
       " 'journal_ref': None,\n",
       " 'pdf_url': 'http://arxiv.org/pdf/1810.04805v2',\n",
       " 'primary_category': 'cs.CL',\n",
       " 'published': datetime.datetime(2018, 10, 11, 0, 50, 1, tzinfo=datetime.timezone.utc),\n",
       " 'summary': 'We introduce a new language representation model called BERT, which stands\\nfor Bidirectional Encoder Representations from Transformers. Unlike recent\\nlanguage representation models, BERT is designed to pre-train deep\\nbidirectional representations from unlabeled text by jointly conditioning on\\nboth left and right context in all layers. As a result, the pre-trained BERT\\nmodel can be fine-tuned with just one additional output layer to create\\nstate-of-the-art models for a wide range of tasks, such as question answering\\nand language inference, without substantial task-specific architecture\\nmodifications.\\n  BERT is conceptually simple and empirically powerful. It obtains new\\nstate-of-the-art results on eleven natural language processing tasks, including\\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\\naccuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\\n(5.1 point absolute improvement).',\n",
       " 'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding',\n",
       " 'updated': datetime.datetime(2019, 5, 24, 20, 37, 26, tzinfo=datetime.timezone.utc)}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    'authors': papers_add[50].authors,\n",
    "    'categories': papers_add[50].categories,\n",
    "    'comment': papers_add[50].comment,\n",
    "    'doi': papers_add[50].doi,\n",
    "    'entry_id': papers_add[50].entry_id,\n",
    "    'journal_ref': papers_add[50].journal_ref,\n",
    "    'pdf_url': papers_add[50].pdf_url,\n",
    "    'primary_category': papers_add[50].primary_category,\n",
    "    'published': papers_add[50].published,\n",
    "    'summary': papers_add[50].summary,\n",
    "    'title': papers_add[50].title,\n",
    "    'updated': papers_add[50].updated\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>comment</th>\n",
       "      <th>doi</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christop...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>CVPR 2022; Code: https://github.com/facebookre...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2201.03545v2</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2201.03545</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2022-01-10 18:59:10+00:00</td>\n",
       "      <td>The \"Roaring 20s\" of visual recognition began ...</td>\n",
       "      <td>A ConvNet for the 2020s</td>\n",
       "      <td>2022-03-02 15:08:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan W...</td>\n",
       "      <td>[cs.CV, cs.LG]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2103.14030v2</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2103.14030</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2021-03-25 17:59:31+00:00</td>\n",
       "      <td>This paper presents a new vision Transformer, ...</td>\n",
       "      <td>Swin Transformer: Hierarchical Vision Transfor...</td>\n",
       "      <td>2021-08-17 16:41:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Alexey Dosovitskiy, Lucas Beyer, Alexander Ko...</td>\n",
       "      <td>[cs.CV, cs.AI, cs.LG]</td>\n",
       "      <td>Fine-tuning code and pre-trained models are av...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2010.11929v2</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2010.11929</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2020-10-22 17:55:59+00:00</td>\n",
       "      <td>While the Transformer architecture has become ...</td>\n",
       "      <td>An Image is Worth 16x16 Words: Transformers fo...</td>\n",
       "      <td>2021-06-03 13:08:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Dan Friedman, Alexander Wettig, Danqi Chen]</td>\n",
       "      <td>[cs.LG, cs.CL]</td>\n",
       "      <td>Our code, and example Transformer Programs, ar...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2306.01128v1</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2306.01128</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2023-06-01 20:27:01+00:00</td>\n",
       "      <td>Recent research in mechanistic interpretabilit...</td>\n",
       "      <td>Learning Transformer Programs</td>\n",
       "      <td>2023-06-01 20:27:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Lingjiao Chen, Matei Zaharia, James Zou]</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CL, cs.SE]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2305.05176v1</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2305.05176</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2023-05-09 05:11:02+00:00</td>\n",
       "      <td>There is a rapidly growing number of large lan...</td>\n",
       "      <td>FrugalGPT: How to Use Large Language Models Wh...</td>\n",
       "      <td>2023-05-09 05:11:02+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "0  [Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christop...   \n",
       "1  [Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan W...   \n",
       "2  [Alexey Dosovitskiy, Lucas Beyer, Alexander Ko...   \n",
       "3       [Dan Friedman, Alexander Wettig, Danqi Chen]   \n",
       "4          [Lingjiao Chen, Matei Zaharia, James Zou]   \n",
       "\n",
       "                     categories  \\\n",
       "0                       [cs.CV]   \n",
       "1                [cs.CV, cs.LG]   \n",
       "2         [cs.CV, cs.AI, cs.LG]   \n",
       "3                [cs.LG, cs.CL]   \n",
       "4  [cs.LG, cs.AI, cs.CL, cs.SE]   \n",
       "\n",
       "                                             comment   doi  \\\n",
       "0  CVPR 2022; Code: https://github.com/facebookre...  None   \n",
       "1                                               None  None   \n",
       "2  Fine-tuning code and pre-trained models are av...  None   \n",
       "3  Our code, and example Transformer Programs, ar...  None   \n",
       "4                                               None  None   \n",
       "\n",
       "                            entry_id journal_ref  \\\n",
       "0  http://arxiv.org/abs/2201.03545v2        None   \n",
       "1  http://arxiv.org/abs/2103.14030v2        None   \n",
       "2  http://arxiv.org/abs/2010.11929v2        None   \n",
       "3  http://arxiv.org/abs/2306.01128v1        None   \n",
       "4  http://arxiv.org/abs/2305.05176v1        None   \n",
       "\n",
       "                           pdf_url primary_category                 published  \\\n",
       "0  http://arxiv.org/pdf/2201.03545            cs.CV 2022-01-10 18:59:10+00:00   \n",
       "1  http://arxiv.org/pdf/2103.14030            cs.CV 2021-03-25 17:59:31+00:00   \n",
       "2  http://arxiv.org/pdf/2010.11929            cs.CV 2020-10-22 17:55:59+00:00   \n",
       "3  http://arxiv.org/pdf/2306.01128            cs.LG 2023-06-01 20:27:01+00:00   \n",
       "4  http://arxiv.org/pdf/2305.05176            cs.LG 2023-05-09 05:11:02+00:00   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The \"Roaring 20s\" of visual recognition began ...   \n",
       "1  This paper presents a new vision Transformer, ...   \n",
       "2  While the Transformer architecture has become ...   \n",
       "3  Recent research in mechanistic interpretabilit...   \n",
       "4  There is a rapidly growing number of large lan...   \n",
       "\n",
       "                                               title                   updated  \n",
       "0                            A ConvNet for the 2020s 2022-03-02 15:08:16+00:00  \n",
       "1  Swin Transformer: Hierarchical Vision Transfor... 2021-08-17 16:41:34+00:00  \n",
       "2  An Image is Worth 16x16 Words: Transformers fo... 2021-06-03 13:08:56+00:00  \n",
       "3                      Learning Transformer Programs 2023-06-01 20:27:01+00:00  \n",
       "4  FrugalGPT: How to Use Large Language Models Wh... 2023-05-09 05:11:02+00:00  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_add = []\n",
    "\n",
    "for result in papers_add:\n",
    "    result.pdf_url = re.sub(r'v\\d+$', '', result.pdf_url)\n",
    "\n",
    "    dataset_add.append({\n",
    "        'authors': result.authors,\n",
    "        'categories': result.categories,\n",
    "        'comment': result.comment,\n",
    "        'doi': result.doi,\n",
    "        'entry_id': result.entry_id,\n",
    "        'journal_ref': result.journal_ref,\n",
    "        'pdf_url': result.pdf_url,\n",
    "        'primary_category': result.primary_category,\n",
    "        'published': result.published,\n",
    "        'summary': result.summary,\n",
    "        'title': result.title,\n",
    "        'updated': result.updated\n",
    "    })\n",
    "\n",
    "dataset_add = pd.DataFrame(dataset_add)\n",
    "dataset_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_add.to_json('dataset_add.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't read file from url: https://export.arxiv.org/pdf/2307.02486, due to error: No /Root object! - Is this really a PDF?\n"
     ]
    }
   ],
   "source": [
    "all_text_add = []\n",
    "for pdf_url in dataset_add['pdf_url']:\n",
    "    pdf_url = \"https://export.\"+pdf_url.split(\"://\")[-1]\n",
    "    text = ''\n",
    "\n",
    "    r = requests.get(pdf_url)\n",
    "    with open(\"temp.pdf\", \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    try:\n",
    "        text = extract_text(\"temp.pdf\")\n",
    "    except Exception as e:\n",
    "        print(f\"Couldn't read file from url: {pdf_url}, due to error: {str(e)}\")\n",
    "\n",
    "    all_text_add.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_add['text'] = all_text_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>comment</th>\n",
       "      <th>doi</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>journal_ref</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>published</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>updated</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christop...</td>\n",
       "      <td>[cs.CV]</td>\n",
       "      <td>CVPR 2022; Code: https://github.com/facebookre...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2201.03545v2</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2201.03545</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2022-01-10 18:59:10+00:00</td>\n",
       "      <td>The \"Roaring 20s\" of visual recognition began ...</td>\n",
       "      <td>A ConvNet for the 2020s</td>\n",
       "      <td>2022-03-02 15:08:16+00:00</td>\n",
       "      <td>A ConvNet for the 2020s\\n\\nZhuang Liu1,2* Hanz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan W...</td>\n",
       "      <td>[cs.CV, cs.LG]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2103.14030v2</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2103.14030</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2021-03-25 17:59:31+00:00</td>\n",
       "      <td>This paper presents a new vision Transformer, ...</td>\n",
       "      <td>Swin Transformer: Hierarchical Vision Transfor...</td>\n",
       "      <td>2021-08-17 16:41:34+00:00</td>\n",
       "      <td>Swin Transformer: Hierarchical Vision Transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Alexey Dosovitskiy, Lucas Beyer, Alexander Ko...</td>\n",
       "      <td>[cs.CV, cs.AI, cs.LG]</td>\n",
       "      <td>Fine-tuning code and pre-trained models are av...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2010.11929v2</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2010.11929</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2020-10-22 17:55:59+00:00</td>\n",
       "      <td>While the Transformer architecture has become ...</td>\n",
       "      <td>An Image is Worth 16x16 Words: Transformers fo...</td>\n",
       "      <td>2021-06-03 13:08:56+00:00</td>\n",
       "      <td>1\\n2\\n0\\n2\\n\\nn\\nu\\nJ\\n\\n3\\n\\n]\\n\\nV\\nC\\n.\\ns\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Dan Friedman, Alexander Wettig, Danqi Chen]</td>\n",
       "      <td>[cs.LG, cs.CL]</td>\n",
       "      <td>Our code, and example Transformer Programs, ar...</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2306.01128v1</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2306.01128</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2023-06-01 20:27:01+00:00</td>\n",
       "      <td>Recent research in mechanistic interpretabilit...</td>\n",
       "      <td>Learning Transformer Programs</td>\n",
       "      <td>2023-06-01 20:27:01+00:00</td>\n",
       "      <td>3\\n2\\n0\\n2\\n\\nn\\nu\\nJ\\n\\n1\\n\\n]\\n\\nG\\nL\\n.\\ns\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Lingjiao Chen, Matei Zaharia, James Zou]</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CL, cs.SE]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/abs/2305.05176v1</td>\n",
       "      <td>None</td>\n",
       "      <td>http://arxiv.org/pdf/2305.05176</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>2023-05-09 05:11:02+00:00</td>\n",
       "      <td>There is a rapidly growing number of large lan...</td>\n",
       "      <td>FrugalGPT: How to Use Large Language Models Wh...</td>\n",
       "      <td>2023-05-09 05:11:02+00:00</td>\n",
       "      <td>3\\n2\\n0\\n2\\n\\ny\\na\\nM\\n9\\n\\n]\\n\\nG\\nL\\n.\\ns\\nc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             authors  \\\n",
       "0  [Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christop...   \n",
       "1  [Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan W...   \n",
       "2  [Alexey Dosovitskiy, Lucas Beyer, Alexander Ko...   \n",
       "3       [Dan Friedman, Alexander Wettig, Danqi Chen]   \n",
       "4          [Lingjiao Chen, Matei Zaharia, James Zou]   \n",
       "\n",
       "                     categories  \\\n",
       "0                       [cs.CV]   \n",
       "1                [cs.CV, cs.LG]   \n",
       "2         [cs.CV, cs.AI, cs.LG]   \n",
       "3                [cs.LG, cs.CL]   \n",
       "4  [cs.LG, cs.AI, cs.CL, cs.SE]   \n",
       "\n",
       "                                             comment   doi  \\\n",
       "0  CVPR 2022; Code: https://github.com/facebookre...  None   \n",
       "1                                               None  None   \n",
       "2  Fine-tuning code and pre-trained models are av...  None   \n",
       "3  Our code, and example Transformer Programs, ar...  None   \n",
       "4                                               None  None   \n",
       "\n",
       "                            entry_id journal_ref  \\\n",
       "0  http://arxiv.org/abs/2201.03545v2        None   \n",
       "1  http://arxiv.org/abs/2103.14030v2        None   \n",
       "2  http://arxiv.org/abs/2010.11929v2        None   \n",
       "3  http://arxiv.org/abs/2306.01128v1        None   \n",
       "4  http://arxiv.org/abs/2305.05176v1        None   \n",
       "\n",
       "                           pdf_url primary_category                 published  \\\n",
       "0  http://arxiv.org/pdf/2201.03545            cs.CV 2022-01-10 18:59:10+00:00   \n",
       "1  http://arxiv.org/pdf/2103.14030            cs.CV 2021-03-25 17:59:31+00:00   \n",
       "2  http://arxiv.org/pdf/2010.11929            cs.CV 2020-10-22 17:55:59+00:00   \n",
       "3  http://arxiv.org/pdf/2306.01128            cs.LG 2023-06-01 20:27:01+00:00   \n",
       "4  http://arxiv.org/pdf/2305.05176            cs.LG 2023-05-09 05:11:02+00:00   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The \"Roaring 20s\" of visual recognition began ...   \n",
       "1  This paper presents a new vision Transformer, ...   \n",
       "2  While the Transformer architecture has become ...   \n",
       "3  Recent research in mechanistic interpretabilit...   \n",
       "4  There is a rapidly growing number of large lan...   \n",
       "\n",
       "                                               title  \\\n",
       "0                            A ConvNet for the 2020s   \n",
       "1  Swin Transformer: Hierarchical Vision Transfor...   \n",
       "2  An Image is Worth 16x16 Words: Transformers fo...   \n",
       "3                      Learning Transformer Programs   \n",
       "4  FrugalGPT: How to Use Large Language Models Wh...   \n",
       "\n",
       "                    updated                                               text  \n",
       "0 2022-03-02 15:08:16+00:00  A ConvNet for the 2020s\\n\\nZhuang Liu1,2* Hanz...  \n",
       "1 2021-08-17 16:41:34+00:00  Swin Transformer: Hierarchical Vision Transfor...  \n",
       "2 2021-06-03 13:08:56+00:00  1\\n2\\n0\\n2\\n\\nn\\nu\\nJ\\n\\n3\\n\\n]\\n\\nV\\nC\\n.\\ns\\...  \n",
       "3 2023-06-01 20:27:01+00:00  3\\n2\\n0\\n2\\n\\nn\\nu\\nJ\\n\\n1\\n\\n]\\n\\nG\\nL\\n.\\ns\\...  \n",
       "4 2023-05-09 05:11:02+00:00  3\\n2\\n0\\n2\\n\\ny\\na\\nM\\n9\\n\\n]\\n\\nG\\nL\\n.\\ns\\nc...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 empty strings in the text column.\n",
      "There are 1 empty strings or strings containing only whitespace in the text column.\n"
     ]
    }
   ],
   "source": [
    "empty_strings = (dataset_add['text'] == '').sum()\n",
    "print(f'There are {empty_strings} empty strings in the text column.')\n",
    "\n",
    "empty_or_whitespace_strings = (dataset_add['text'].str.strip() == '').sum()\n",
    "print(f'There are {empty_or_whitespace_strings} empty strings or strings containing only whitespace in the text column.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_add_clean = dataset_add[dataset_add['text'] != '']\n",
    "dataset_add_clean.to_json(\"arxiv_data_add_clean.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
